{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67012821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "from wzh.transformer import Transformer\n",
    "\n",
    "torch.manual_seed(0)\n",
    "learning_rate = 1e-5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dataset = load_dataset(\"data/wikitext103\", \"wikitext-103-v1\")\n",
    "dataset = load_dataset(\n",
    "    \"data/wikitext103/\",\n",
    "    data_files={\n",
    "        \"train\": [\"train-00000-of-00002.parquet\",\"train-00001-of-00002.parquet\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./gpt2-tokenizer\")\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "\n",
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dim_model = 384\n",
    "        self.embedding = nn.Embedding(vocab_size, dim_model)\n",
    "        self.model = Transformer(\n",
    "            nlayer=6,\n",
    "            dim_model=dim_model,\n",
    "            num_head=8,\n",
    "            max_seq_len=1024,\n",
    "            glu_attn=False,\n",
    "        )\n",
    "        self.output = nn.Linear(dim_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.model(x, mask)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GLUAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dim_model = 384\n",
    "        self.embedding = nn.Embedding(vocab_size, dim_model)\n",
    "        self.model = Transformer(\n",
    "            nlayer=6,\n",
    "            dim_model=dim_model,\n",
    "            num_head=8,\n",
    "            max_seq_len=1024,\n",
    "            glu_attn=True,\n",
    "        )\n",
    "        self.output = nn.Linear(dim_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.embedding(x)\n",
    "        x = self.model(x, mask)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def prepare_data(example):\n",
    "    tokens = tokenizer(example[\"text\"], truncation=True, max_length=1024)\n",
    "    return {\"input_ids\": tokens[\"input_ids\"], \"labels\": tokens[\"input_ids\"]}\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    prepare_data, remove_columns=dataset[\"train\"].column_names\n",
    ")\n",
    "\n",
    "\n",
    "def collate_fn(examples):\n",
    "    input_ids = [torch.tensor(x[\"input_ids\"], dtype=torch.long) for x in examples]\n",
    "    input_ids = nn.utils.rnn.pad_sequence(input_ids, batch_first=True)\n",
    "    labels = input_ids.clone()\n",
    "    return {\"input_ids\": input_ids, \"labels\": labels}\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_dataset[\"train\"],\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "def train(model, num_epochs):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    print(f\"parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(model)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    num_token_list = []\n",
    "    loss_list = []\n",
    "    ema_loss = 8\n",
    "    total_tokens = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            seq_len = input_ids.size(1)\n",
    "            if seq_len == 0:\n",
    "                continue\n",
    "            total_tokens += seq_len\n",
    "            mask = torch.triu(\n",
    "                torch.ones((seq_len, seq_len), dtype=torch.bool, device=device),\n",
    "                diagonal=1,\n",
    "            )\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids, mask)\n",
    "            loss = criterion(\n",
    "                logits[:, :-1].view(-1, vocab_size), labels[:, 1:].view(-1)\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            ema_loss = 0.999 * ema_loss + 0.001 * loss.item()\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": f\"{loss.item():.4f}\",\n",
    "                    \"ema loss\": f\"{ema_loss:.4f}\",\n",
    "                }\n",
    "            )\n",
    "            num_token_list.append(total_tokens)\n",
    "            loss_list.append(loss.item())\n",
    "        scheduler.step()\n",
    "    return num_token_list, loss_list\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_and_average(list, num_splits=100):\n",
    "    split_indices = np.linspace(0, len(list), num_splits + 1, dtype=int)\n",
    "    avg = []\n",
    "\n",
    "    for i in range(len(split_indices) - 1):\n",
    "        start_idx = split_indices[i]\n",
    "        end_idx = split_indices[i + 1]\n",
    "        avg.append(np.mean(list[start_idx:end_idx]))\n",
    "\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ab071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 49,297,489\n",
      "Baseline(\n",
      "  (embedding): Embedding(50257, 384)\n",
      "  (model): Transformer(\n",
      "    (pe): PositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerLayer(\n",
      "        (attn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadSelfAttention(\n",
      "          (wq): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wk): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wv): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wo): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): GLUFeedForward(\n",
      "          (linear1): Linear(in_features=384, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Linear(in_features=384, out_features=50257, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1801350/1801350 [11:20:45<00:00, 44.10it/s, loss=5.4937, ema loss=4.1913]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[592633.1344206008, 1775149.7129613734, 2968149.7804291844, 4153741.575487083, 5341142.065236052, 6515029.654077253, 7696866.1204188485, 8883754.95888412, 10068568.441373391, 11251683.641459227, 12428944.038709125, 13600162.233133048, 14777525.638540773, 15961294.550768174, 17137959.51287554, 18324709.603261802, 19498156.652961373, 20687730.848940004, 21862212.824034333, 23027673.436394848, 24209810.060767315, 25388208.0616309, 26558684.936223175, 27745798.69776824, 28931265.443309586, 30096726.689527895, 31272323.802918456, 32442116.755128317, 33622678.421630904, 34790034.54892704, 35959152.56798283, 37134680.75521415, 38314104.41862661, 39493853.57793991, 40670731.13037507, 41854448.36051502, 43038176.97133047, 44230061.0430006, 45417589.04214592, 46605326.939484976, 47775253.101030044, 48935971.257831946, 50097247.880515024, 51269839.88789699, 52456797.68955454, 53626359.88248927, 54799712.562918454, 55979029.2639485, 57150185.287958115, 58331884.7344206, 59508089.19484978, 60687455.68002746, 61866366.53459228, 63051331.882317595, 64233566.26334764, 65408960.6211484, 66576755.5711588, 67763158.82849786, 68938034.20633422, 70107397.02051502, 71288202.48369099, 72473399.5383691, 73654178.41035104, 74831683.87064378, 76023438.0613734, 77189084.51137242, 78355391.96995708, 79533654.83012876, 80700559.03295854, 81875001.94841202, 83044611.44334763, 84217756.35012875, 85397554.2611793, 86578252.08008584, 87747526.06746781, 88920381.20470347, 90105317.37854077, 91275634.25493562, 92453240.01484978, 93637530.06437215, 94824680.71656652, 95985729.60523605, 97155829.30512403, 98334167.87536481, 99527053.85613734, 100709529.19613734, 101884329.14736933, 103058905.54660945, 104247235.00206009, 105423609.6763368, 106608688.29733905, 107803782.63107297, 108996924.60618025, 110164943.37267187, 111336665.62772532, 112507843.96909872, 113678400.48931423, 114850697.47364807, 116024219.97381975, 117200789.04248562]\n",
      "[6.131883070469542, 5.645558278481016, 5.508757337313385, 5.3417416411591, 5.267807060791571, 5.2085467677867205, 5.168269355090498, 5.126523595922287, 5.077145056179824, 5.021980026806885, 4.990156596127628, 4.9392496547102125, 4.948144489273893, 4.9114285237380075, 4.902996705309867, 4.8495973435613475, 4.877668184982893, 4.7945320892039245, 4.789504505537066, 4.785033948165065, 4.748196978582421, 4.709598469894875, 4.676284721709804, 4.715556344395432, 4.6468727719477565, 4.669991142060927, 4.6659940176319665, 4.641396114489337, 4.614266332281922, 4.6025565518242155, 4.6093041452352965, 4.5934475566382895, 4.596684017853708, 4.58288551654139, 4.562450152852135, 4.576350119041734, 4.5381735531291865, 4.530688605562643, 4.510190466392841, 4.530379869153108, 4.478927917745955, 4.471834360597169, 4.486399758428239, 4.485269666593921, 4.466860870874199, 4.481677289732888, 4.453938833677126, 4.4480671405018395, 4.437075030450224, 4.426215011978306, 4.409472701732517, 4.416667005483167, 4.418142169947724, 4.423017209990774, 4.402227075047743, 4.379500505018846, 4.375883860041351, 4.394011448571466, 4.367711150412192, 4.372471004212235, 4.35878388464171, 4.355615204593982, 4.348501912571844, 4.355394102876902, 4.335586831581983, 4.32038210212671, 4.319036705382928, 4.299025665457268, 4.32192801991731, 4.314833192394831, 4.309477405072202, 4.288069233692175, 4.304135467117364, 4.2822516096188075, 4.296162205668238, 4.294798230815018, 4.267104075685215, 4.265034250924004, 4.271684496793017, 4.293695190504165, 4.272382896460049, 4.243947818814717, 4.267202081382416, 4.250895370783308, 4.253345194278133, 4.256478200947842, 4.232196483153726, 4.251763675573038, 4.26073003007187, 4.227706796405604, 4.234572969169512, 4.231117065405002, 4.206093098350477, 4.217383028193573, 4.217441584343898, 4.199143812286311, 4.199819294014136, 4.1933887625765855, 4.201584737830168, 4.182920244802205]\n"
     ]
    }
   ],
   "source": [
    "token_list, loss_list = train(Baseline(), 1)\n",
    "token_list = split_and_average(token_list, 100)\n",
    "loss_list = split_and_average(loss_list, 100)\n",
    "print(token_list)\n",
    "print(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "914af448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: 49,298,257\n",
      "GLUAttention(\n",
      "  (embedding): Embedding(50257, 384)\n",
      "  (model): Transformer(\n",
      "    (pe): PositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerLayer(\n",
      "        (attn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadSelfAttention(\n",
      "          (wq): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wk): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wv): Linear(in_features=384, out_features=512, bias=True)\n",
      "          (wo): Linear(in_features=256, out_features=384, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): GLUFeedForward(\n",
      "          (linear1): Linear(in_features=384, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Linear(in_features=384, out_features=50257, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1801350/1801350 [11:25:35<00:00, 43.79it/s, loss=4.3933, ema loss=4.1295]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[596162.9970815451, 1777169.3688412018, 2951576.5273819743, 4117972.13320745, 5283359.27751073, 6458656.3527897, 7645470.674534375, 8813815.348927038, 9991150.129957082, 11182892.41665236, 12361578.900008583, 13548502.643175965, 14723169.877167381, 15903577.51231654, 17081740.72506438, 18249885.009785406, 19423068.302918456, 20595076.49343404, 21772772.33725322, 22959193.63776824, 24135818.6656081, 25323836.541545063, 26503390.407639485, 27682442.862832617, 28860831.480645437, 30050872.03527897, 31233208.808669526, 32417826.863702685, 33594352.2239485, 34772230.56377682, 35955628.710042916, 37112733.17174491, 38295110.33716738, 39475797.15793991, 40644346.893914685, 41828210.1551073, 43005617.9016309, 44178361.13003176, 45357282.39879829, 46531243.32643777, 47712569.941287555, 48899660.843017764, 50082577.42120171, 51258110.96060086, 52425548.410351045, 53605747.40532189, 54789417.777939916, 55971035.037854075, 57159731.88026779, 58346734.57321888, 59536176.34437768, 60723895.23131061, 61901971.74334764, 63082814.51072961, 64270486.92927039, 65450051.04111235, 66638396.802403435, 67825149.40609442, 68996135.2768861, 70173400.403691, 71348535.75776824, 72522481.03545064, 73692231.25499958, 74870061.49390557, 76060646.53622317, 77230205.85323149, 78404503.78429185, 79582717.95218883, 80755454.06454381, 81928534.53236051, 83106645.56480686, 84280881.29433477, 85452326.68328899, 86632137.72549357, 87801417.80377683, 88972442.818728, 90148998.16360515, 91325822.86772533, 92498836.27021459, 93668615.36855206, 94849369.75742489, 96019507.33476394, 97194372.80190541, 98377008.62034334, 99549715.19965665, 100723327.07098712, 101892705.40468629, 103070110.52592275, 104256517.65725322, 105429523.99313363, 106606938.11236052, 107772670.49751073, 108952425.71879828, 110128697.20264354, 111300924.89742489, 112480968.8006867, 113662334.06016651, 114843302.02446352, 116037379.28291845, 117217336.11870226]\n",
      "[6.244448548202351, 5.6592393197714, 5.482652739401859, 5.384811709147596, 5.269603680504462, 5.236313585118259, 5.1481338868435795, 5.083368113341665, 5.075047375887569, 5.028454234359282, 4.988145097525511, 4.943902374009238, 4.9126239179317785, 4.88132751999444, 4.837820314754264, 4.823337849420076, 4.820695842374995, 4.824899340732676, 4.797681180043666, 4.776621462825062, 4.735176551045836, 4.755425931616834, 4.696480874399387, 4.698291962450698, 4.648751880784292, 4.6520096879842585, 4.630997570820568, 4.651275892515562, 4.597831520701363, 4.613852590170126, 4.562053301577085, 4.568775703151167, 4.572621502527576, 4.529498825439975, 4.541253794945311, 4.538055576723021, 4.5131687598517205, 4.517122780121491, 4.493608951454287, 4.489155704946829, 4.496488108569197, 4.5084712185618, 4.466195976199351, 4.458504039139403, 4.416292811028577, 4.425283319577135, 4.44766155523316, 4.440681825680219, 4.422911999198803, 4.402745530170592, 4.40914011737004, 4.400355666076729, 4.3628477821944385, 4.369442967010798, 4.362030650402535, 4.3647705015351335, 4.367937881420427, 4.361256914736919, 4.336241220408435, 4.356463815295237, 4.332222415140106, 4.317548784003253, 4.31869376581163, 4.312130441141551, 4.319736535337558, 4.291593727129777, 4.304867983142498, 4.307393732096664, 4.282660816818626, 4.294158814151296, 4.276740734302979, 4.251555521008698, 4.290871811608456, 4.253820077454264, 4.229246363691634, 4.242516598781888, 4.228696844226684, 4.251442511694449, 4.225522301452006, 4.250349728008485, 4.237165442726899, 4.226027832070741, 4.2350418128389915, 4.235601311437725, 4.199131170193197, 4.239042826256127, 4.184819410975043, 4.213374490169208, 4.213280364574561, 4.206133354231814, 4.195335895957689, 4.209416483337171, 4.182760021666368, 4.174207046180962, 4.1806531632211374, 4.207684717167333, 4.150291756720686, 4.186028854732558, 4.180033716018333, 4.1576464595652824]\n"
     ]
    }
   ],
   "source": [
    "token_list, loss_list = train(GLUAttention(), 1)\n",
    "token_list = split_and_average(token_list, 100)\n",
    "loss_list = split_and_average(loss_list, 100)\n",
    "print(token_list)\n",
    "print(loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
