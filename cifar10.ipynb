{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch, math, time\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from wzh.transformer import Transformer\n",
    "\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(torch.__version__)\n",
    "device = \"cuda\"\n",
    "\n",
    "n_class = 10\n",
    "\n",
    "patch_shape = (4, 4)\n",
    "d_patch = math.prod(patch_shape) * 3\n",
    "n_patch = 3 * 32 * 32 // d_patch\n",
    "\n",
    "dropout = 0.0\n",
    "epochs = 20\n",
    "batch_size = 384\n",
    "learn_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dim_model = 384\n",
    "        self.embedding = nn.Linear(d_patch, dim_model)\n",
    "        self.model = Transformer(\n",
    "            nlayer=6,\n",
    "            dim_model=dim_model,\n",
    "            num_head=8,\n",
    "            max_seq_len=n_patch,\n",
    "            glu_attn=False,\n",
    "        )\n",
    "        self.output = nn.Linear(dim_model, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.unfold(x, patch_shape, stride=patch_shape).mT\n",
    "        x = self.embedding(x)\n",
    "        x = self.model(x)\n",
    "        x = self.output(x)\n",
    "        x = x.mean(-1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GLUAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        dim_model = 384\n",
    "        self.embedding = nn.Linear(d_patch, dim_model)\n",
    "        self.model = Transformer(\n",
    "            nlayer=6,\n",
    "            dim_model=dim_model,\n",
    "            num_head=8,\n",
    "            max_seq_len=n_patch,\n",
    "            glu_attn=True,\n",
    "        )\n",
    "        self.output = nn.Linear(dim_model, n_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.unfold(x, patch_shape, stride=patch_shape).mT\n",
    "        x = self.embedding(x)\n",
    "        x = self.model(x)\n",
    "        x = self.output(x)\n",
    "        x = x.mean(-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    total_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    avg_loss, acc = 0, 0\n",
    "    for i, (source, target) in enumerate(dataloader):\n",
    "        source: Tensor = source.to(device, non_blocking=True)\n",
    "        target: Tensor = target.to(device, non_blocking=True)\n",
    "        pred = model(source)\n",
    "        loss = loss_fn(pred, target)\n",
    "        loss.backward(), optimizer.step(), optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            avg_loss += loss.item()\n",
    "            acc += (pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "    avg_loss /= num_batches\n",
    "    acc /= size\n",
    "    total_time = time.time() - total_time\n",
    "    return (acc, avg_loss, total_time)\n",
    "\n",
    "\n",
    "def val(dataloader, model, loss_fn):\n",
    "    total_time = time.time()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    avg_loss, acc = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for source, target in dataloader:\n",
    "            source: Tensor = source.to(device, non_blocking=True)\n",
    "            target: Tensor = target.to(device, non_blocking=True)\n",
    "            pred = model(source)\n",
    "            avg_loss += loss_fn(pred, target).item()\n",
    "            acc += (pred.argmax(1) == target).type(torch.float).sum().item()\n",
    "    avg_loss /= num_batches\n",
    "    acc /= size\n",
    "    total_time = time.time() - total_time\n",
    "    return (acc, avg_loss, total_time)\n",
    "\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandAugment(num_ops=2, magnitude=10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.RandomErasing(\n",
    "            p=0.2, scale=(0.02, 0.33), ratio=(0.3, 3.3), value=0, inplace=False\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ]\n",
    ")\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train,\n",
    ")\n",
    "val_data = datasets.CIFAR10(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline(\n",
      "  (embedding): Linear(in_features=48, out_features=384, bias=True)\n",
      "  (model): Transformer(\n",
      "    (pe): PositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerLayer(\n",
      "        (attn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadSelfAttention(\n",
      "          (wq): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wk): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wv): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wo): Linear(in_features=384, out_features=384, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): GLUFeedForward(\n",
      "          (linear1): Linear(in_features=384, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Linear(in_features=384, out_features=10, bias=True)\n",
      ")\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.153,     0.203,  2.308979,  2.076312,      28.5,       3.4,      32.0\n",
      "    2,     0.207,     0.288,  2.065633,  1.875094,      28.5,       3.4,      63.9\n",
      "    3,     0.283,     0.376,  1.909344,  1.671285,      28.4,       3.4,      95.7\n",
      "    4,     0.337,     0.414,  1.774548,  1.592713,      28.4,       3.4,     127.6\n",
      "    5,     0.386,     0.476,  1.655107,  1.426879,      28.4,       3.4,     159.5\n",
      "    6,     0.429,     0.517,  1.550020,  1.323968,      28.4,       3.4,     191.4\n",
      "    7,     0.468,     0.554,  1.467685,  1.249228,      28.5,       3.4,     223.3\n",
      "    8,     0.499,     0.573,  1.385779,  1.188101,      28.4,       3.4,     255.2\n",
      "    9,     0.529,     0.594,  1.312526,  1.121814,      28.5,       3.4,     287.1\n",
      "   10,     0.540,     0.619,  1.269059,  1.048149,      28.4,       3.4,     318.9\n",
      "   11,     0.561,     0.632,  1.220848,  1.011551,      28.4,       3.4,     350.8\n",
      "   12,     0.575,     0.646,  1.179082,  0.982060,      28.4,       3.4,     382.7\n",
      "   13,     0.587,     0.657,  1.149323,  0.941679,      28.4,       3.4,     414.6\n",
      "   14,     0.597,     0.665,  1.122903,  0.919772,      28.4,       3.4,     446.4\n",
      "   15,     0.609,     0.671,  1.098079,  0.901128,      28.4,       3.4,     478.3\n",
      "   16,     0.616,     0.674,  1.076042,  0.893168,      28.5,       3.4,     510.2\n",
      "   17,     0.617,     0.685,  1.065830,  0.873091,      28.4,       3.4,     542.1\n",
      "   18,     0.623,     0.679,  1.057889,  0.875586,      28.4,       3.4,     573.9\n",
      "   19,     0.625,     0.683,  1.050591,  0.865712,      28.4,       3.4,     605.8\n",
      "   20,     0.624,     0.685,  1.048353,  0.865236,      28.4,       3.4,     637.6\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.152,     0.213,  2.311683,  2.073325,      28.5,       3.4,      31.9\n",
      "    2,     0.210,     0.304,  2.072316,  1.857523,      28.5,       3.5,      63.8\n",
      "    3,     0.284,     0.385,  1.891709,  1.686452,      28.5,       3.4,      95.7\n",
      "    4,     0.349,     0.429,  1.744696,  1.558416,      28.4,       3.4,     127.6\n",
      "    5,     0.399,     0.485,  1.635226,  1.417526,      28.4,       3.5,     159.5\n",
      "    6,     0.451,     0.539,  1.526731,  1.293319,      28.5,       3.4,     191.4\n",
      "    7,     0.489,     0.561,  1.428460,  1.217989,      28.4,       3.4,     223.3\n",
      "    8,     0.515,     0.599,  1.353823,  1.128161,      28.5,       3.5,     255.2\n",
      "    9,     0.544,     0.604,  1.280267,  1.081688,      28.4,       3.4,     287.1\n",
      "   10,     0.561,     0.638,  1.228016,  1.007445,      28.5,       3.5,     319.0\n",
      "   11,     0.575,     0.645,  1.184299,  0.986857,      28.5,       3.5,     350.9\n",
      "   12,     0.590,     0.641,  1.146322,  0.984242,      28.4,       3.5,     382.8\n",
      "   13,     0.602,     0.661,  1.116057,  0.932590,      28.4,       3.4,     414.7\n",
      "   14,     0.610,     0.679,  1.089105,  0.894116,      28.4,       3.4,     446.5\n",
      "   15,     0.619,     0.679,  1.066460,  0.876731,      28.4,       3.4,     478.4\n",
      "   16,     0.628,     0.681,  1.044566,  0.876003,      28.4,       3.4,     510.3\n",
      "   17,     0.633,     0.691,  1.032065,  0.857074,      28.4,       3.4,     542.2\n",
      "   18,     0.637,     0.691,  1.027355,  0.849057,      28.5,       3.4,     574.1\n",
      "   19,     0.637,     0.692,  1.018277,  0.847888,      28.4,       3.4,     606.0\n",
      "   20,     0.642,     0.691,  1.014593,  0.846682,      28.4,       3.4,     637.8\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.154,     0.217,  2.314078,  2.068220,      28.5,       3.4,      31.9\n",
      "    2,     0.210,     0.303,  2.066626,  1.843545,      28.4,       3.4,      63.8\n",
      "    3,     0.290,     0.364,  1.887432,  1.723736,      28.4,       3.4,      95.7\n",
      "    4,     0.348,     0.425,  1.749273,  1.548869,      28.5,       3.5,     127.6\n",
      "    5,     0.395,     0.481,  1.643619,  1.427805,      28.4,       3.5,     159.4\n",
      "    6,     0.444,     0.538,  1.533584,  1.320951,      28.4,       3.5,     191.3\n",
      "    7,     0.485,     0.564,  1.432847,  1.228631,      28.5,       3.5,     223.2\n",
      "    8,     0.514,     0.593,  1.351070,  1.130987,      28.4,       3.4,     255.1\n",
      "    9,     0.540,     0.624,  1.284369,  1.052333,      28.5,       3.5,     287.0\n",
      "   10,     0.560,     0.645,  1.224601,  1.000643,      28.5,       3.5,     318.9\n",
      "   11,     0.579,     0.639,  1.181573,  1.011290,      28.4,       3.4,     350.8\n",
      "   12,     0.589,     0.662,  1.152282,  0.941133,      28.5,       3.4,     382.7\n",
      "   13,     0.603,     0.668,  1.119978,  0.926540,      28.4,       3.4,     414.6\n",
      "   14,     0.610,     0.677,  1.089323,  0.891092,      28.4,       3.4,     446.4\n",
      "   15,     0.619,     0.682,  1.069270,  0.883781,      28.4,       3.4,     478.3\n",
      "   16,     0.628,     0.685,  1.053811,  0.869975,      28.4,       3.5,     510.2\n",
      "   17,     0.633,     0.690,  1.039191,  0.849237,      28.4,       3.4,     542.0\n",
      "   18,     0.635,     0.695,  1.029103,  0.843888,      28.5,       3.5,     573.9\n",
      "   19,     0.638,     0.696,  1.022611,  0.842128,      28.5,       3.4,     605.8\n",
      "   20,     0.637,     0.697,  1.016628,  0.838962,      28.5,       3.4,     637.7\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.157,     0.216,  2.300251,  2.043467,      28.5,       3.4,      31.9\n",
      "    2,     0.225,     0.320,  2.042333,  1.808537,      28.4,       3.4,      63.8\n",
      "    3,     0.296,     0.383,  1.873741,  1.668824,      28.5,       3.5,      95.7\n",
      "    4,     0.350,     0.433,  1.746338,  1.530323,      28.4,       3.4,     127.6\n",
      "    5,     0.399,     0.488,  1.639535,  1.424675,      28.5,       3.4,     159.5\n",
      "    6,     0.439,     0.501,  1.545115,  1.399793,      28.4,       3.4,     191.3\n",
      "    7,     0.475,     0.551,  1.461422,  1.245581,      28.5,       3.4,     223.2\n",
      "    8,     0.503,     0.569,  1.379866,  1.192484,      28.5,       3.4,     255.1\n",
      "    9,     0.526,     0.602,  1.320717,  1.116013,      28.4,       3.4,     287.0\n",
      "   10,     0.544,     0.613,  1.267698,  1.064836,      28.4,       3.4,     318.9\n",
      "   11,     0.563,     0.640,  1.217742,  1.023921,      28.4,       3.4,     350.8\n",
      "   12,     0.578,     0.648,  1.187326,  0.988297,      28.5,       3.4,     382.7\n",
      "   13,     0.591,     0.665,  1.151509,  0.952673,      28.4,       3.4,     414.5\n",
      "   14,     0.601,     0.671,  1.117938,  0.928528,      28.4,       3.5,     446.4\n",
      "   15,     0.608,     0.673,  1.102414,  0.918195,      28.5,       3.4,     478.3\n",
      "   16,     0.615,     0.678,  1.085212,  0.905884,      28.4,       3.4,     510.2\n",
      "   17,     0.621,     0.684,  1.069675,  0.885764,      28.4,       3.4,     542.1\n",
      "   18,     0.622,     0.685,  1.061860,  0.884302,      28.5,       3.4,     574.0\n",
      "   19,     0.628,     0.689,  1.050118,  0.875552,      28.5,       3.4,     605.9\n",
      "   20,     0.627,     0.688,  1.050809,  0.875342,      28.5,       3.4,     637.8\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.152,     0.197,  2.307905,  2.078411,      28.5,       3.4,      31.9\n",
      "    2,     0.206,     0.283,  2.081331,  1.882954,      28.4,       3.5,      63.8\n",
      "    3,     0.273,     0.368,  1.928154,  1.707886,      28.4,       3.4,      95.6\n",
      "    4,     0.348,     0.429,  1.755598,  1.534296,      28.4,       3.4,     127.5\n",
      "    5,     0.401,     0.480,  1.637847,  1.424474,      28.4,       3.4,     159.4\n",
      "    6,     0.450,     0.533,  1.530336,  1.300556,      28.5,       3.4,     191.3\n",
      "    7,     0.488,     0.568,  1.429255,  1.203766,      28.5,       3.4,     223.2\n",
      "    8,     0.517,     0.588,  1.347596,  1.146964,      28.4,       3.4,     255.0\n",
      "    9,     0.536,     0.622,  1.291490,  1.067262,      28.4,       3.4,     286.9\n",
      "   10,     0.556,     0.623,  1.243338,  1.044036,      28.5,       3.4,     318.8\n",
      "   11,     0.570,     0.639,  1.201296,  0.998979,      28.4,       3.4,     350.7\n",
      "   12,     0.584,     0.658,  1.169334,  0.952367,      28.4,       3.4,     382.6\n",
      "   13,     0.597,     0.666,  1.126541,  0.951451,      28.4,       3.4,     414.4\n",
      "   14,     0.604,     0.675,  1.111392,  0.901970,      28.5,       3.4,     446.3\n",
      "   15,     0.611,     0.676,  1.090596,  0.900927,      28.5,       3.4,     478.2\n",
      "   16,     0.620,     0.686,  1.067402,  0.877113,      28.5,       3.4,     510.1\n",
      "   17,     0.626,     0.689,  1.054413,  0.869075,      28.4,       3.5,     542.0\n",
      "   18,     0.625,     0.688,  1.051300,  0.868339,      28.5,       3.4,     573.9\n",
      "   19,     0.629,     0.691,  1.042183,  0.862267,      28.4,       3.4,     605.8\n",
      "   20,     0.633,     0.691,  1.033909,  0.861853,      28.4,       3.4,     637.7\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.152,     0.217,  2.312184,  2.064138,      28.4,       3.5,      31.9\n",
      "    2,     0.217,     0.301,  2.059450,  1.867675,      28.5,       3.4,      63.8\n",
      "    3,     0.285,     0.368,  1.901157,  1.710271,      28.4,       3.5,      95.7\n",
      "    4,     0.343,     0.443,  1.767931,  1.534369,      28.5,       3.4,     127.6\n",
      "    5,     0.398,     0.486,  1.643856,  1.431132,      28.4,       3.5,     159.5\n",
      "    6,     0.437,     0.520,  1.552320,  1.346716,      28.5,       3.5,     191.4\n",
      "    7,     0.474,     0.555,  1.462451,  1.239336,      28.4,       3.5,     223.3\n",
      "    8,     0.506,     0.575,  1.382627,  1.185992,      28.4,       3.4,     255.1\n",
      "    9,     0.527,     0.601,  1.312808,  1.114538,      28.4,       3.4,     287.0\n",
      "   10,     0.549,     0.613,  1.264435,  1.085330,      28.5,       3.5,     318.9\n",
      "   11,     0.565,     0.643,  1.211188,  1.010100,      28.5,       3.5,     350.8\n",
      "   12,     0.578,     0.649,  1.182605,  0.970809,      28.5,       3.4,     382.7\n",
      "   13,     0.590,     0.660,  1.151254,  0.944534,      28.4,       3.4,     414.6\n",
      "   14,     0.599,     0.669,  1.124331,  0.923420,      28.4,       3.5,     446.5\n",
      "   15,     0.605,     0.676,  1.104593,  0.918610,      28.4,       3.4,     478.4\n",
      "   16,     0.617,     0.673,  1.077828,  0.907629,      28.4,       3.4,     510.3\n",
      "   17,     0.621,     0.683,  1.063712,  0.884734,      28.5,       3.5,     542.2\n",
      "   18,     0.625,     0.686,  1.057737,  0.883403,      28.4,       3.4,     574.1\n",
      "   19,     0.627,     0.686,  1.052895,  0.877900,      28.5,       3.5,     606.0\n",
      "   20,     0.630,     0.690,  1.044080,  0.873778,      28.5,       3.4,     637.9\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.151,     0.212,  2.312422,  2.051984,      28.4,       3.4,      31.9\n",
      "    2,     0.217,     0.323,  2.051841,  1.826137,      28.5,       3.4,      63.8\n",
      "    3,     0.294,     0.371,  1.883735,  1.682027,      28.4,       3.4,      95.7\n",
      "    4,     0.350,     0.439,  1.751289,  1.528066,      28.5,       3.5,     127.6\n",
      "    5,     0.395,     0.477,  1.648796,  1.438384,      28.4,       3.4,     159.4\n",
      "    6,     0.431,     0.515,  1.563256,  1.370818,      28.5,       3.5,     191.4\n",
      "    7,     0.465,     0.542,  1.480226,  1.272952,      28.4,       3.4,     223.2\n",
      "    8,     0.488,     0.573,  1.414492,  1.195043,      28.4,       3.5,     255.1\n",
      "    9,     0.517,     0.600,  1.340227,  1.125475,      28.4,       3.4,     287.0\n",
      "   10,     0.538,     0.614,  1.286505,  1.084883,      28.4,       3.5,     318.9\n",
      "   11,     0.550,     0.613,  1.248457,  1.069135,      28.4,       3.4,     350.7\n",
      "   12,     0.565,     0.633,  1.213887,  1.025758,      28.4,       3.5,     382.6\n",
      "   13,     0.578,     0.644,  1.178232,  1.002902,      28.4,       3.4,     414.5\n",
      "   14,     0.585,     0.665,  1.154355,  0.952213,      28.5,       3.4,     446.4\n",
      "   15,     0.596,     0.668,  1.135996,  0.935884,      28.4,       3.5,     478.3\n",
      "   16,     0.605,     0.670,  1.111709,  0.920634,      28.4,       3.4,     510.2\n",
      "   17,     0.607,     0.675,  1.102297,  0.904996,      28.5,       3.4,     542.1\n",
      "   18,     0.613,     0.678,  1.084325,  0.904803,      28.5,       3.5,     574.0\n",
      "   19,     0.615,     0.677,  1.082510,  0.899532,      28.4,       3.4,     605.9\n",
      "   20,     0.616,     0.676,  1.082001,  0.898568,      28.4,       3.4,     637.8\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.153,     0.206,  2.320869,  2.064465,      28.4,       3.4,      31.9\n",
      "    2,     0.213,     0.325,  2.063093,  1.826192,      28.5,       3.5,      63.8\n",
      "    3,     0.298,     0.373,  1.871471,  1.670050,      28.4,       3.5,      95.7\n",
      "    4,     0.357,     0.452,  1.739765,  1.511290,      28.4,       3.4,     127.5\n",
      "    5,     0.413,     0.498,  1.612321,  1.401908,      28.4,       3.4,     159.4\n",
      "    6,     0.460,     0.514,  1.494690,  1.345833,      28.4,       3.4,     191.3\n",
      "    7,     0.499,     0.582,  1.394686,  1.173645,      28.5,       3.4,     223.2\n",
      "    8,     0.529,     0.610,  1.317692,  1.090210,      28.5,       3.5,     255.1\n",
      "    9,     0.546,     0.626,  1.261171,  1.041231,      28.4,       3.4,     287.0\n",
      "   10,     0.568,     0.634,  1.208797,  1.025278,      28.4,       3.4,     318.9\n",
      "   11,     0.580,     0.641,  1.171899,  0.998107,      28.4,       3.5,     350.8\n",
      "   12,     0.597,     0.658,  1.132713,  0.943044,      28.4,       3.4,     382.6\n",
      "   13,     0.604,     0.675,  1.108065,  0.916453,      28.4,       3.4,     414.5\n",
      "   14,     0.616,     0.679,  1.075202,  0.894309,      28.5,       3.5,     446.4\n",
      "   15,     0.624,     0.681,  1.054104,  0.891515,      28.4,       3.4,     478.3\n",
      "   16,     0.630,     0.695,  1.038717,  0.845881,      28.5,       3.4,     510.2\n",
      "   17,     0.636,     0.693,  1.022776,  0.861847,      28.5,       3.4,     542.1\n",
      "   18,     0.640,     0.700,  1.014406,  0.835199,      28.4,       3.4,     574.0\n",
      "   19,     0.644,     0.701,  1.007947,  0.836604,      28.4,       3.4,     605.9\n",
      "   20,     0.645,     0.700,  0.998960,  0.837941,      28.5,       3.4,     637.8\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.157,     0.233,  2.298645,  2.031582,      28.4,       3.4,      31.9\n",
      "    2,     0.215,     0.265,  2.057166,  1.881720,      28.5,       3.4,      63.8\n",
      "    3,     0.286,     0.371,  1.894824,  1.678412,      28.4,       3.4,      95.6\n",
      "    4,     0.349,     0.417,  1.748777,  1.577542,      28.4,       3.4,     127.5\n",
      "    5,     0.397,     0.463,  1.633983,  1.445648,      28.4,       3.4,     159.4\n",
      "    6,     0.442,     0.518,  1.541921,  1.368610,      28.4,       3.4,     191.2\n",
      "    7,     0.481,     0.555,  1.449563,  1.231059,      28.4,       3.4,     223.1\n",
      "    8,     0.510,     0.584,  1.358342,  1.161411,      28.4,       3.4,     255.0\n",
      "    9,     0.534,     0.606,  1.296510,  1.096211,      28.4,       3.4,     286.8\n",
      "   10,     0.553,     0.622,  1.246196,  1.067275,      28.5,       3.4,     318.7\n",
      "   11,     0.569,     0.636,  1.207400,  1.010454,      28.4,       3.5,     350.6\n",
      "   12,     0.580,     0.645,  1.176299,  0.986811,      28.4,       3.5,     382.5\n",
      "   13,     0.593,     0.662,  1.141955,  0.949147,      28.4,       3.4,     414.4\n",
      "   14,     0.604,     0.668,  1.111717,  0.933393,      28.4,       3.4,     446.3\n",
      "   15,     0.616,     0.674,  1.085792,  0.908940,      28.4,       3.4,     478.1\n",
      "   16,     0.617,     0.686,  1.079717,  0.887605,      28.4,       3.4,     510.0\n",
      "   17,     0.625,     0.687,  1.058932,  0.881475,      28.4,       3.4,     541.9\n",
      "   18,     0.628,     0.686,  1.048892,  0.876619,      28.4,       3.4,     573.7\n",
      "   19,     0.630,     0.688,  1.042279,  0.874073,      28.4,       3.4,     605.6\n",
      "   20,     0.631,     0.690,  1.037910,  0.871141,      28.5,       3.4,     637.5\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.150,     0.203,  2.311597,  2.062352,      28.4,       3.4,      31.9\n",
      "    2,     0.215,     0.306,  2.054865,  1.875032,      28.4,       3.4,      63.8\n",
      "    3,     0.293,     0.401,  1.876231,  1.626053,      28.4,       3.5,      95.6\n",
      "    4,     0.355,     0.448,  1.741603,  1.521237,      28.4,       3.4,     127.5\n",
      "    5,     0.405,     0.499,  1.626904,  1.401339,      28.4,       3.4,     159.4\n",
      "    6,     0.451,     0.527,  1.522234,  1.308187,      28.5,       3.5,     191.3\n",
      "    7,     0.481,     0.568,  1.437255,  1.192777,      28.4,       3.4,     223.2\n",
      "    8,     0.511,     0.590,  1.362781,  1.155089,      28.4,       3.4,     255.1\n",
      "    9,     0.530,     0.604,  1.306681,  1.110303,      28.5,       3.5,     287.0\n",
      "   10,     0.549,     0.624,  1.257938,  1.042385,      28.5,       3.4,     318.9\n",
      "   11,     0.569,     0.642,  1.207006,  1.000912,      28.4,       3.5,     350.8\n",
      "   12,     0.583,     0.653,  1.171884,  0.967956,      28.4,       3.4,     382.7\n",
      "   13,     0.596,     0.657,  1.138590,  0.947684,      28.5,       3.4,     414.6\n",
      "   14,     0.603,     0.666,  1.114537,  0.938027,      28.4,       3.4,     446.4\n",
      "   15,     0.610,     0.666,  1.095494,  0.935345,      28.5,       3.4,     478.4\n",
      "   16,     0.616,     0.681,  1.079838,  0.891528,      28.4,       3.4,     510.2\n",
      "   17,     0.623,     0.686,  1.056070,  0.876789,      28.4,       3.4,     542.1\n",
      "   18,     0.624,     0.690,  1.056229,  0.863745,      28.4,       3.5,     574.0\n",
      "   19,     0.630,     0.690,  1.041963,  0.866926,      28.4,       3.4,     605.9\n",
      "   20,     0.629,     0.693,  1.041200,  0.864177,      28.4,       3.4,     637.7\n",
      "GLUAttention(\n",
      "  (embedding): Linear(in_features=48, out_features=384, bias=True)\n",
      "  (model): Transformer(\n",
      "    (pe): PositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x TransformerLayer(\n",
      "        (attn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiHeadSelfAttention(\n",
      "          (wq): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wk): Linear(in_features=384, out_features=384, bias=True)\n",
      "          (wv): Linear(in_features=384, out_features=512, bias=True)\n",
      "          (wo): Linear(in_features=256, out_features=384, bias=True)\n",
      "        )\n",
      "        (ffn_norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (ffn): GLUFeedForward(\n",
      "          (linear1): Linear(in_features=384, out_features=2048, bias=True)\n",
      "          (linear2): Linear(in_features=1024, out_features=384, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output): Linear(in_features=384, out_features=10, bias=True)\n",
      ")\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.153,     0.219,  2.310334,  2.018294,      28.8,       3.5,      32.2\n",
      "    2,     0.223,     0.316,  2.022375,  1.807806,      28.8,       3.5,      64.5\n",
      "    3,     0.300,     0.385,  1.850281,  1.651751,      28.8,       3.5,      96.7\n",
      "    4,     0.359,     0.447,  1.722766,  1.505317,      28.8,       3.5,     129.0\n",
      "    5,     0.403,     0.496,  1.617674,  1.400803,      28.8,       3.5,     161.2\n",
      "    6,     0.448,     0.543,  1.527798,  1.282800,      28.8,       3.5,     193.5\n",
      "    7,     0.484,     0.561,  1.428983,  1.225407,      28.8,       3.5,     225.8\n",
      "    8,     0.510,     0.585,  1.366110,  1.150930,      28.8,       3.5,     258.0\n",
      "    9,     0.534,     0.601,  1.309857,  1.122729,      28.8,       3.5,     290.3\n",
      "   10,     0.551,     0.626,  1.255590,  1.045642,      28.8,       3.5,     322.6\n",
      "   11,     0.564,     0.634,  1.224616,  1.018639,      28.8,       3.5,     354.8\n",
      "   12,     0.575,     0.652,  1.189256,  0.980958,      28.8,       3.5,     387.0\n",
      "   13,     0.591,     0.651,  1.150452,  0.965461,      28.8,       3.5,     419.3\n",
      "   14,     0.598,     0.666,  1.130947,  0.935771,      28.8,       3.5,     451.6\n",
      "   15,     0.606,     0.674,  1.105465,  0.913263,      28.8,       3.5,     483.9\n",
      "   16,     0.607,     0.673,  1.100508,  0.920544,      28.8,       3.5,     516.2\n",
      "   17,     0.614,     0.673,  1.081264,  0.906633,      28.8,       3.5,     548.4\n",
      "   18,     0.620,     0.675,  1.072254,  0.898519,      28.8,       3.5,     580.7\n",
      "   19,     0.620,     0.677,  1.063598,  0.892810,      28.8,       3.5,     612.9\n",
      "   20,     0.620,     0.679,  1.064539,  0.889894,      28.8,       3.5,     645.2\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.151,     0.220,  2.334948,  2.026801,      28.8,       3.5,      32.3\n",
      "    2,     0.230,     0.327,  2.015969,  1.784302,      28.8,       3.5,      64.6\n",
      "    3,     0.307,     0.383,  1.856229,  1.653350,      28.8,       3.5,      96.8\n",
      "    4,     0.369,     0.480,  1.717547,  1.473821,      28.8,       3.5,     129.1\n",
      "    5,     0.422,     0.517,  1.596749,  1.343022,      28.8,       3.5,     161.3\n",
      "    6,     0.459,     0.554,  1.495323,  1.246256,      28.8,       3.5,     193.6\n",
      "    7,     0.486,     0.567,  1.424402,  1.216005,      28.8,       3.5,     225.9\n",
      "    8,     0.516,     0.602,  1.344795,  1.115223,      28.8,       3.5,     258.1\n",
      "    9,     0.535,     0.616,  1.295319,  1.072866,      28.8,       3.5,     290.4\n",
      "   10,     0.554,     0.628,  1.250315,  1.039855,      28.8,       3.5,     322.7\n",
      "   11,     0.566,     0.632,  1.214241,  1.018726,      28.8,       3.5,     354.9\n",
      "   12,     0.582,     0.654,  1.176481,  0.972993,      28.8,       3.5,     387.2\n",
      "   13,     0.586,     0.670,  1.153794,  0.942638,      28.8,       3.5,     419.5\n",
      "   14,     0.595,     0.674,  1.126902,  0.920982,      28.8,       3.5,     451.8\n",
      "   15,     0.605,     0.672,  1.109539,  0.907617,      28.9,       3.6,     484.3\n",
      "   16,     0.612,     0.682,  1.091603,  0.891734,      29.0,       3.5,     516.8\n",
      "   17,     0.615,     0.684,  1.080040,  0.884552,      28.8,       3.5,     549.1\n",
      "   18,     0.618,     0.689,  1.069042,  0.878755,      28.8,       3.5,     581.3\n",
      "   19,     0.618,     0.689,  1.062881,  0.874759,      28.8,       3.5,     613.6\n",
      "   20,     0.622,     0.687,  1.063034,  0.876842,      28.8,       3.5,     645.8\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.148,     0.214,  2.340452,  2.031143,      28.8,       3.5,      32.3\n",
      "    2,     0.216,     0.302,  2.033128,  1.825722,      28.8,       3.5,      64.5\n",
      "    3,     0.303,     0.391,  1.861456,  1.665316,      28.8,       3.5,      96.8\n",
      "    4,     0.364,     0.459,  1.725563,  1.464898,      28.8,       3.5,     129.0\n",
      "    5,     0.408,     0.487,  1.620699,  1.413343,      28.8,       3.5,     161.3\n",
      "    6,     0.445,     0.528,  1.531996,  1.326154,      28.8,       3.5,     193.5\n",
      "    7,     0.478,     0.561,  1.447739,  1.237149,      28.8,       3.5,     225.7\n",
      "    8,     0.507,     0.582,  1.379071,  1.181769,      28.8,       3.5,     258.0\n",
      "    9,     0.528,     0.600,  1.322438,  1.112756,      28.8,       3.5,     290.2\n",
      "   10,     0.549,     0.627,  1.265127,  1.048066,      28.8,       3.5,     322.5\n",
      "   11,     0.559,     0.638,  1.232870,  1.009665,      28.8,       3.5,     354.7\n",
      "   12,     0.575,     0.649,  1.194731,  0.992213,      28.8,       3.5,     387.0\n",
      "   13,     0.586,     0.651,  1.160805,  0.979980,      28.8,       3.5,     419.2\n",
      "   14,     0.595,     0.667,  1.139693,  0.943038,      28.8,       3.5,     451.5\n",
      "   15,     0.601,     0.674,  1.122488,  0.925969,      28.8,       3.5,     483.7\n",
      "   16,     0.608,     0.677,  1.102293,  0.912653,      28.8,       3.5,     516.0\n",
      "   17,     0.613,     0.682,  1.085881,  0.906599,      28.8,       3.5,     548.2\n",
      "   18,     0.617,     0.680,  1.083680,  0.902827,      28.8,       3.5,     580.5\n",
      "   19,     0.617,     0.683,  1.075735,  0.896303,      28.8,       3.5,     612.7\n",
      "   20,     0.621,     0.684,  1.070880,  0.893351,      28.8,       3.5,     644.9\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.154,     0.206,  2.313843,  2.030256,      28.8,       3.5,      32.3\n",
      "    2,     0.226,     0.314,  2.027004,  1.827676,      28.8,       3.5,      64.5\n",
      "    3,     0.299,     0.395,  1.863764,  1.657415,      28.8,       3.5,      96.8\n",
      "    4,     0.353,     0.425,  1.741149,  1.529042,      28.8,       3.5,     129.1\n",
      "    5,     0.395,     0.464,  1.628624,  1.455590,      28.8,       3.5,     161.3\n",
      "    6,     0.436,     0.519,  1.539086,  1.323213,      28.8,       3.5,     193.5\n",
      "    7,     0.475,     0.558,  1.454573,  1.223170,      28.8,       3.5,     225.7\n",
      "    8,     0.502,     0.591,  1.373810,  1.144877,      28.8,       3.5,     258.0\n",
      "    9,     0.527,     0.604,  1.318214,  1.101987,      28.8,       3.5,     290.3\n",
      "   10,     0.545,     0.626,  1.267866,  1.044056,      28.8,       3.5,     322.5\n",
      "   11,     0.559,     0.636,  1.229675,  1.016814,      28.8,       3.5,     354.8\n",
      "   12,     0.573,     0.644,  1.193256,  0.997682,      28.8,       3.5,     387.0\n",
      "   13,     0.584,     0.652,  1.163449,  0.982705,      28.8,       3.5,     419.3\n",
      "   14,     0.590,     0.658,  1.145049,  0.947736,      28.8,       3.5,     451.5\n",
      "   15,     0.600,     0.665,  1.117368,  0.934274,      28.8,       3.5,     483.7\n",
      "   16,     0.609,     0.672,  1.097997,  0.919571,      28.8,       3.5,     516.0\n",
      "   17,     0.611,     0.673,  1.089878,  0.904234,      28.8,       3.5,     548.2\n",
      "   18,     0.616,     0.679,  1.080651,  0.895888,      28.8,       3.5,     580.5\n",
      "   19,     0.616,     0.677,  1.075311,  0.899755,      28.8,       3.5,     612.7\n",
      "   20,     0.617,     0.678,  1.072212,  0.897788,      28.8,       3.5,     645.0\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.152,     0.220,  2.340769,  2.016518,      28.8,       3.5,      32.2\n",
      "    2,     0.236,     0.329,  2.011069,  1.798825,      28.8,       3.5,      64.5\n",
      "    3,     0.306,     0.404,  1.851707,  1.619784,      28.8,       3.5,      96.7\n",
      "    4,     0.363,     0.455,  1.727970,  1.494931,      28.8,       3.5,     129.0\n",
      "    5,     0.415,     0.502,  1.614937,  1.396347,      28.8,       3.5,     161.2\n",
      "    6,     0.451,     0.543,  1.527289,  1.285272,      28.8,       3.5,     193.5\n",
      "    7,     0.481,     0.565,  1.441643,  1.232845,      28.8,       3.5,     225.8\n",
      "    8,     0.505,     0.578,  1.382888,  1.179650,      28.8,       3.5,     258.0\n",
      "    9,     0.527,     0.611,  1.315129,  1.101756,      28.8,       3.5,     290.3\n",
      "   10,     0.541,     0.625,  1.278350,  1.067676,      28.8,       3.5,     322.6\n",
      "   11,     0.559,     0.635,  1.238234,  1.035269,      28.8,       3.5,     354.8\n",
      "   12,     0.574,     0.644,  1.195014,  1.011616,      28.8,       3.5,     387.0\n",
      "   13,     0.580,     0.654,  1.174382,  0.984577,      28.8,       3.5,     419.3\n",
      "   14,     0.592,     0.662,  1.145970,  0.963538,      28.8,       3.5,     451.5\n",
      "   15,     0.603,     0.671,  1.124335,  0.937735,      28.8,       3.5,     483.8\n",
      "   16,     0.606,     0.669,  1.114641,  0.933693,      28.8,       3.5,     516.0\n",
      "   17,     0.610,     0.680,  1.097548,  0.917878,      28.8,       3.5,     548.3\n",
      "   18,     0.616,     0.682,  1.085519,  0.906134,      28.8,       3.5,     580.5\n",
      "   19,     0.617,     0.680,  1.078439,  0.913097,      28.8,       3.5,     612.8\n",
      "   20,     0.616,     0.684,  1.085194,  0.908319,      28.8,       3.5,     645.0\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.148,     0.212,  2.325285,  2.032411,      28.8,       3.5,      32.3\n",
      "    2,     0.219,     0.293,  2.033643,  1.838254,      28.8,       3.5,      64.5\n",
      "    3,     0.299,     0.383,  1.859401,  1.673353,      28.8,       3.5,      96.7\n",
      "    4,     0.352,     0.449,  1.736061,  1.512793,      28.8,       3.5,     129.0\n",
      "    5,     0.401,     0.477,  1.632303,  1.409388,      28.8,       3.5,     161.2\n",
      "    6,     0.439,     0.522,  1.545558,  1.321790,      28.8,       3.5,     193.5\n",
      "    7,     0.476,     0.561,  1.451546,  1.221526,      28.8,       3.5,     225.8\n",
      "    8,     0.503,     0.586,  1.382966,  1.160626,      28.8,       3.5,     258.0\n",
      "    9,     0.525,     0.602,  1.312464,  1.093255,      28.8,       3.5,     290.3\n",
      "   10,     0.543,     0.625,  1.263807,  1.033073,      28.8,       3.5,     322.5\n",
      "   11,     0.564,     0.636,  1.221699,  1.012852,      28.8,       3.5,     354.8\n",
      "   12,     0.571,     0.642,  1.196157,  0.984729,      28.8,       3.5,     387.0\n",
      "   13,     0.590,     0.649,  1.153024,  0.978345,      28.8,       3.5,     419.3\n",
      "   14,     0.597,     0.666,  1.134020,  0.935913,      28.8,       3.5,     451.5\n",
      "   15,     0.606,     0.666,  1.111371,  0.932616,      28.8,       3.5,     483.8\n",
      "   16,     0.609,     0.673,  1.096875,  0.908831,      28.8,       3.5,     516.0\n",
      "   17,     0.613,     0.678,  1.086480,  0.893939,      28.8,       3.5,     548.3\n",
      "   18,     0.617,     0.681,  1.070903,  0.891868,      28.8,       3.5,     580.6\n",
      "   19,     0.620,     0.686,  1.065881,  0.883133,      28.8,       3.5,     612.8\n",
      "   20,     0.621,     0.684,  1.064325,  0.883054,      28.8,       3.5,     645.0\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.149,     0.191,  2.331756,  2.056735,      28.8,       3.5,      32.3\n",
      "    2,     0.231,     0.333,  2.018752,  1.775597,      28.8,       3.5,      64.5\n",
      "    3,     0.306,     0.402,  1.850247,  1.621655,      28.8,       3.5,      96.7\n",
      "    4,     0.346,     0.409,  1.745536,  1.581729,      28.8,       3.5,     129.0\n",
      "    5,     0.386,     0.477,  1.654082,  1.416776,      28.8,       3.5,     161.2\n",
      "    6,     0.429,     0.495,  1.557390,  1.428663,      28.8,       3.5,     193.5\n",
      "    7,     0.466,     0.534,  1.479643,  1.289731,      28.8,       3.5,     225.7\n",
      "    8,     0.494,     0.558,  1.408645,  1.231661,      28.8,       3.5,     258.0\n",
      "    9,     0.509,     0.592,  1.356673,  1.120753,      28.8,       3.5,     290.2\n",
      "   10,     0.533,     0.604,  1.300570,  1.093245,      28.8,       3.5,     322.4\n",
      "   11,     0.543,     0.619,  1.267549,  1.055407,      28.8,       3.5,     354.7\n",
      "   12,     0.557,     0.634,  1.232091,  1.022691,      28.8,       3.5,     386.9\n",
      "   13,     0.572,     0.644,  1.193749,  0.993998,      28.8,       3.5,     419.2\n",
      "   14,     0.575,     0.651,  1.177885,  0.971345,      28.8,       3.5,     451.4\n",
      "   15,     0.585,     0.656,  1.156919,  0.952823,      28.8,       3.5,     483.7\n",
      "   16,     0.593,     0.665,  1.135774,  0.939748,      28.8,       3.5,     515.9\n",
      "   17,     0.598,     0.670,  1.122704,  0.925870,      28.8,       3.5,     548.1\n",
      "   18,     0.600,     0.667,  1.113381,  0.925867,      28.8,       3.5,     580.4\n",
      "   19,     0.606,     0.669,  1.107699,  0.925015,      28.8,       3.5,     612.7\n",
      "   20,     0.607,     0.671,  1.103545,  0.920931,      28.8,       3.5,     644.9\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.151,     0.209,  2.319669,  2.020315,      28.8,       3.5,      32.2\n",
      "    2,     0.226,     0.337,  2.021353,  1.786202,      28.8,       3.5,      64.5\n",
      "    3,     0.301,     0.389,  1.855628,  1.652194,      28.8,       3.5,      96.7\n",
      "    4,     0.345,     0.434,  1.744725,  1.553148,      28.8,       3.5,     128.9\n",
      "    5,     0.390,     0.479,  1.650264,  1.426472,      28.8,       3.5,     161.2\n",
      "    6,     0.434,     0.520,  1.563969,  1.334782,      28.8,       3.5,     193.5\n",
      "    7,     0.465,     0.549,  1.481058,  1.252581,      28.8,       3.5,     225.7\n",
      "    8,     0.492,     0.563,  1.398236,  1.199944,      28.8,       3.5,     258.0\n",
      "    9,     0.518,     0.595,  1.342324,  1.130258,      28.8,       3.5,     290.2\n",
      "   10,     0.535,     0.600,  1.297418,  1.102140,      28.8,       3.5,     322.4\n",
      "   11,     0.549,     0.620,  1.258569,  1.050738,      28.8,       3.5,     354.7\n",
      "   12,     0.564,     0.641,  1.215143,  0.998152,      28.8,       3.5,     386.9\n",
      "   13,     0.572,     0.643,  1.192008,  0.990944,      28.8,       3.5,     419.1\n",
      "   14,     0.582,     0.655,  1.166490,  0.959534,      28.8,       3.5,     451.4\n",
      "   15,     0.591,     0.662,  1.142435,  0.949554,      28.8,       3.5,     483.6\n",
      "   16,     0.596,     0.666,  1.130752,  0.934127,      28.8,       3.5,     515.8\n",
      "   17,     0.600,     0.667,  1.119401,  0.923288,      28.8,       3.5,     548.1\n",
      "   18,     0.606,     0.670,  1.102893,  0.919511,      28.8,       3.5,     580.3\n",
      "   19,     0.606,     0.670,  1.094951,  0.915533,      28.8,       3.5,     612.6\n",
      "   20,     0.609,     0.670,  1.091703,  0.914193,      28.8,       3.5,     644.8\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.152,     0.213,  2.320911,  2.026524,      28.8,       3.5,      32.3\n",
      "    2,     0.235,     0.334,  2.007754,  1.795809,      28.8,       3.5,      64.6\n",
      "    3,     0.308,     0.384,  1.842695,  1.646573,      28.8,       3.5,      96.8\n",
      "    4,     0.363,     0.452,  1.716795,  1.484560,      28.8,       3.5,     129.0\n",
      "    5,     0.412,     0.489,  1.608583,  1.385454,      28.8,       3.5,     161.3\n",
      "    6,     0.455,     0.532,  1.513123,  1.285777,      28.8,       3.5,     193.5\n",
      "    7,     0.487,     0.571,  1.424886,  1.185846,      28.8,       3.5,     225.8\n",
      "    8,     0.517,     0.606,  1.348161,  1.095328,      28.8,       3.5,     258.0\n",
      "    9,     0.539,     0.615,  1.285635,  1.059929,      28.8,       3.5,     290.2\n",
      "   10,     0.558,     0.636,  1.234595,  1.008775,      28.8,       3.5,     322.5\n",
      "   11,     0.567,     0.655,  1.213018,  0.968752,      28.8,       3.5,     354.7\n",
      "   12,     0.585,     0.658,  1.166205,  0.963201,      28.8,       3.5,     386.9\n",
      "   13,     0.592,     0.668,  1.139455,  0.932091,      28.8,       3.5,     419.2\n",
      "   14,     0.604,     0.675,  1.117591,  0.915760,      28.8,       3.5,     451.4\n",
      "   15,     0.610,     0.683,  1.091324,  0.891047,      28.8,       3.5,     483.7\n",
      "   16,     0.614,     0.686,  1.083166,  0.879487,      28.8,       3.5,     516.0\n",
      "   17,     0.619,     0.690,  1.071204,  0.868178,      28.8,       3.5,     548.2\n",
      "   18,     0.624,     0.692,  1.055823,  0.863619,      28.8,       3.5,     580.5\n",
      "   19,     0.629,     0.694,  1.046092,  0.857374,      28.8,       3.5,     612.7\n",
      "   20,     0.628,     0.694,  1.046268,  0.857303,      28.8,       3.5,     644.9\n",
      "epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\n",
      "    1,     0.153,     0.222,  2.331744,  2.040515,      28.8,       3.5,      32.3\n",
      "    2,     0.222,     0.299,  2.034231,  1.823885,      28.8,       3.5,      64.5\n",
      "    3,     0.288,     0.382,  1.879056,  1.654927,      28.8,       3.5,      96.8\n",
      "    4,     0.344,     0.433,  1.756806,  1.518177,      28.8,       3.5,     129.0\n",
      "    5,     0.387,     0.474,  1.644831,  1.422810,      28.8,       3.5,     161.3\n",
      "    6,     0.420,     0.491,  1.558611,  1.398767,      28.8,       3.5,     193.5\n",
      "    7,     0.465,     0.555,  1.475471,  1.249985,      28.8,       3.5,     225.8\n",
      "    8,     0.493,     0.579,  1.404360,  1.164176,      28.8,       3.5,     258.0\n",
      "    9,     0.518,     0.588,  1.346168,  1.148933,      28.8,       3.5,     290.3\n",
      "   10,     0.535,     0.617,  1.294836,  1.053865,      28.8,       3.5,     322.5\n",
      "   11,     0.555,     0.623,  1.241576,  1.039223,      28.8,       3.5,     354.8\n",
      "   12,     0.564,     0.644,  1.211652,  0.994051,      28.8,       3.5,     387.0\n",
      "   13,     0.580,     0.656,  1.180055,  0.968101,      28.8,       3.5,     419.3\n",
      "   14,     0.590,     0.657,  1.154347,  0.956120,      28.8,       3.5,     451.5\n",
      "   15,     0.596,     0.659,  1.133566,  0.937787,      28.8,       3.5,     483.8\n",
      "   16,     0.602,     0.671,  1.111846,  0.905413,      28.8,       3.5,     516.0\n",
      "   17,     0.604,     0.673,  1.099432,  0.903402,      28.8,       3.5,     548.3\n",
      "   18,     0.610,     0.676,  1.093411,  0.899860,      28.8,       3.5,     580.5\n",
      "   19,     0.615,     0.680,  1.075594,  0.893375,      28.8,       3.5,     612.8\n",
      "   20,     0.616,     0.680,  1.077950,  0.890250,      28.8,       3.5,     645.0\n"
     ]
    }
   ],
   "source": [
    "model_list: list[nn.Module] = [Baseline, GLUAttention]\n",
    "\n",
    "for model_creator in model_list:\n",
    "    for i in range(10):\n",
    "        model = model_creator().to(device)\n",
    "        if i == 0:\n",
    "            print(model)\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            train_data, batch_size, shuffle=True, num_workers=4, pin_memory=True\n",
    "        )\n",
    "        val_dataloader = DataLoader(\n",
    "            val_data, batch_size, num_workers=4, pin_memory=True\n",
    "        )\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), learn_rate)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "        train_total_time = 0\n",
    "        val_total_time = 0\n",
    "        print(\n",
    "            \"epoch, train acc,   val acc,train loss,  val loss,train time,  val time,total time\"\n",
    "        )\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            (train_acc, train_loss, train_time) = train(\n",
    "                train_dataloader, model, loss_fn, optimizer\n",
    "            )\n",
    "            scheduler.step()\n",
    "            (val_acc, val_loss, val_time) = val(val_dataloader, model, loss_fn)\n",
    "            train_total_time += train_time\n",
    "            val_total_time += val_time\n",
    "\n",
    "            print(\n",
    "                f\"{epoch:>5},{train_acc:>10.3f},{val_acc:>10.3f},{train_loss:>10f},{val_loss:>10f},{train_time:>10.1f},{val_time:>10.1f},{train_total_time + val_total_time:>10.1f}\"\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
